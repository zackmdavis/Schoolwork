#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 2cm
\bottommargin 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Pinpointing the Generalized Factorial
\end_layout

\begin_layout Author
Zack M.
 Davis
\end_layout

\begin_layout Date
May 2025
\end_layout

\begin_layout Section
Prelude: A Historical Accident
\end_layout

\begin_layout Standard
Driven ceaselessly by a compulsion to generalize, students of mathematics
 often wonder whether there exists an analogue of the factorial function
 
\begin_inset Formula $n!:=\prod_{k=1}^{n}k$
\end_inset

 that works for non-integers.
 The question is traditionally answered in the affirmative by presenting
 a function 
\begin_inset Formula $\Gamma$
\end_inset

 defined on 
\begin_inset Formula $\mathbb{R}$
\end_inset

 (and indeed 
\begin_inset Formula $\mathbb{C}$
\end_inset

) for which 
\begin_inset Formula $\Gamma(x)=(x-1)!$
\end_inset

.
\end_layout

\begin_layout Standard
This reply prompts an obvious followup query: 
\begin_inset Quotes eld
\end_inset

Thanks, but what's with the shift by one? This function is generalizing
 the factorial.
 You should define it such that 
\begin_inset Formula $\Gamma(x)=x!$
\end_inset

, right?
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
In the present author's research, no one seems to have a good answer to
 this.
 It seems like Adrien-Marie Legendre chose 
\begin_inset Formula $\Gamma(n)=(n-1)!$
\end_inset

 back in the early 19th century and it somehow caught on, even though Carl
 Friedrich Gauss was contemporaneously working with the same function (up
 to the shift) as 
\begin_inset Formula $\Pi(n):=n!$
\end_inset

.
 
\end_layout

\begin_layout Standard
Some authors try to rationalize Legendre's blunder by arguing that it's
 better to have the rightmost singularity at 
\begin_inset Formula $0$
\end_inset

 than 
\begin_inset Formula $-1$
\end_inset

, or that we should integrate over the Haar measure.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout

\emph on
https://mathoverflow.net/questions/20960/why-is-the-gamma-function-shifted-from-t
he-factorial-by-1
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The present author doesn't buy it.
 In the spirit of efforts to promote 
\begin_inset Formula $\tau:=2\pi$
\end_inset

 rather than 
\begin_inset Formula $\pi$
\end_inset

 as the correct circle constant in accordance with logic and in opposition
 to blind historical inertia,
\begin_inset Foot
status collapsed

\begin_layout Plain Layout

\emph on
https://www.tauday.com/tau-manifesto
\end_layout

\end_inset

 this report concerns itself with the true generalized factorial 
\begin_inset Formula $\Pi$
\end_inset

 rather than the treacherous so-called 
\begin_inset Quotes eld
\end_inset

gamma function
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $\Gamma$
\end_inset

.
 
\end_layout

\begin_layout Section
The Only Reasonable Way To Do It
\end_layout

\begin_layout Standard
We want a continuous function 
\begin_inset Formula $\Pi(x)$
\end_inset

 that generalizes the factorial: how might we go about engineering such
 a function?
\end_layout

\begin_layout Subsection
The Obvious First Guess (Which Is Wrong)
\end_layout

\begin_layout Standard
We want 
\begin_inset Formula $\Pi(n)=n!$
\end_inset

 for 
\begin_inset Formula $n\in\mathbb{N}$
\end_inset

, a function that interpolates the factorials.
 We're used to approximating functions with power series, which are limits
 of polynomials.
 There is then a natural temptation to consider polynomial interpolations
 of 
\begin_inset Formula $(k,k!)$
\end_inset

 for 
\begin_inset Formula $k\in\{0...n\}$
\end_inset

 and take the limit 
\begin_inset Formula $n\rightarrow\infty$
\end_inset

.
\end_layout

\begin_layout Standard
It turns out that this doesn't work.
 Our standard technique for interpolating points with a polynomial is due
 to Lagrange.
 Suppose we want to interpolate the points 
\begin_inset Formula $(x_{k},y_{k})$
\end_inset

 for 
\begin_inset Formula $k\in\{0...n\}$
\end_inset

.
 We define the Lagrange basis element
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\ell_{k}(x):=\prod_{\substack{0\le j\le n\\
j\ne k
}
}\frac{x-x_{j}}{x_{k}-x_{j}}
\]

\end_inset


\end_layout

\begin_layout Standard
And then
\begin_inset Formula 
\[
P_{n}(x):=\sum_{k}y_{k}\ell_{k}(x)
\]

\end_inset


\end_layout

\begin_layout Standard
The idea is that when 
\begin_inset Formula $x:=x_{k}$
\end_inset

, then for all 
\begin_inset Formula $j\ne k$
\end_inset

, 
\begin_inset Formula $\ell_{j}$
\end_inset

 contains a factor of 
\begin_inset Formula $x_{j}-x_{j}=0$
\end_inset

 so that the 
\begin_inset Formula $y_{j}\ell_{j}(x_{k})$
\end_inset

 term vanishes, and 
\begin_inset Formula $\ell_{k}(x_{k})=\prod_{j\ne k}\frac{x_{k}-x_{j}}{x_{k}-x_{j}}=1$
\end_inset

, engineering the outcome 
\begin_inset Formula $P_{n}(x_{k})=y_{k}$
\end_inset

.
 
\end_layout

\begin_layout Standard
If we apply this method to 
\begin_inset Formula $(x_{k},y_{k}):=(k,k!)$
\end_inset

, we get
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
``\Pi"_{n}(x):=\sum_{k=0}^{n}k!\prod_{\substack{0\le j\le n\\
j\ne k
}
}\frac{x-j}{k-j}
\]

\end_inset


\end_layout

\begin_layout Standard
The naïve hope is that
\begin_inset Formula 
\[
``\Pi"(x):=\lim_{n\rightarrow\infty}\sum_{k=0}^{n}k!\prod_{\substack{0\le j\le n\\
j\ne k
}
}\frac{x-j}{k-j}
\]

\end_inset


\end_layout

\begin_layout Standard
would be our generalized factorial.
 But it doesn't work.
 Our finite polynomial interpolations depended on the 
\begin_inset Formula $\ell_{j}(k)$
\end_inset

 terms vanishing, but when 
\begin_inset Formula $x\notin\mathbb{N}$
\end_inset

, none of the terms vanish: with a factor of 
\begin_inset Formula $k!$
\end_inset

 on each, the series doesn't come close to converging.
\end_layout

\begin_layout Subsection
Using the Recursive Decideratum
\end_layout

\begin_layout Standard
Brute empiricism has failed us.
 A more promising approach might be to work with the desideratum 
\begin_inset Formula 
\begin{equation}
\Pi(x+1)=(x+1)\Pi(x)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
(Note that this is different from the analogous functional equation for
 the treacherous so-called 
\begin_inset Quotes eld
\end_inset

gamma
\begin_inset Quotes erd
\end_inset

 function, 
\begin_inset Formula $\Gamma(x+1)=x\Gamma(x)$
\end_inset

.)
\end_layout

\begin_layout Standard
But what to do with it? 
\end_layout

\begin_layout Standard
As an inspired hack, consider integration by parts—a procedure known to
 sometimes transform an expression into a ``version of itself
\begin_inset Quotes erd
\end_inset

 ``altered
\begin_inset Quotes erd
\end_inset

 by a multplicative factor (as in ``rapid repeated integration by parts
\begin_inset Quotes erd
\end_inset

).
 The integration by parts formula is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\int_{a}^{b}u\,dv=\left.uv\right|_{a}^{b}-\int_{a}^{b}v\,du
\]

\end_inset


\end_layout

\begin_layout Standard
The hope here is that there exist choices of 
\begin_inset Formula $u$
\end_inset

, 
\begin_inset Formula $v$
\end_inset

, 
\begin_inset Formula $a$
\end_inset

, and 
\begin_inset Formula $b$
\end_inset

 that end up satisfying (1):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\underbrace{\int_{a}^{b}u\,dv}_{\Pi(x+1)}=\left.uv\right|_{a}^{b}\underbrace{-\int_{a}^{b}v\,du}_{(x+1)\Pi(x)}
\]

\end_inset


\end_layout

\begin_layout Standard
(We'll worry about the 
\begin_inset Formula $uv$
\end_inset

 term in a moment.)
\end_layout

\begin_layout Standard
A period of contemplation should convince the reader that it suffices to
 take 
\begin_inset Formula $dv=-v$
\end_inset

 and (construing 
\begin_inset Formula $u$
\end_inset

 as taking an argument 
\begin_inset Formula $x$
\end_inset

 different from the one that 
\begin_inset Formula $d$
\end_inset

 indicates differentiation by) 
\begin_inset Formula $du(x+1)=(x+1)\cdot u(x)$
\end_inset

.
 Disciples of the differential and integral calculus who know that the natural
 exponential is its own derivative and integral can use that fact in conjunction
 with the chain rule to infer that (taking the variable we 
\emph on
are
\emph default
 differentiating by as 
\begin_inset Formula $t$
\end_inset

) if 
\begin_inset Formula $v$
\end_inset

 is not zero, then we must have 
\begin_inset Formula $v:=\exp-t$
\end_inset

.
 Such disciples will probably also successfully pattern-match 
\begin_inset Formula $du(x+1)=(x+1)\cdot u(x)$
\end_inset

 to the power rule: 
\begin_inset Formula $\frac{d}{dt}t^{x+1}=(x+1)\cdot t^{x}$
\end_inset

 and conclude that 
\begin_inset Formula $u:=t^{x+1}$
\end_inset

, although it make take some discipline to accept 
\begin_inset Formula $x$
\end_inset

 being a constant concerning differentiation with respect to 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Standard
At this juncture, we have:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\int_{a}^{b}t^{x+1}\exp-t\,dt=\left.t^{x+1}\exp-t\right|_{t=a}^{b}+\int_{a}^{b}(x+1)t^{x}\exp-t\,dt
\]

\end_inset


\end_layout

\begin_layout Standard
Where it remains to worry about the 
\begin_inset Formula $uv$
\end_inset

 term, and settle on a choice of 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

.
 These problems solve each other.
 Instead of 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

, let's use the symbols 
\begin_inset Formula $\varepsilon$
\end_inset

 and 
\begin_inset Formula $R$
\end_inset

 (respectively).
 The perceptive reader can probably tell from the choice of symbols where
 I'm going with this: the 
\begin_inset Formula $\left.t^{x+1}\exp-t\right|_{t=\varepsilon}^{R}$
\end_inset

 terms cancel in the limit:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\lim_{\varepsilon\rightarrow0}\lim_{R\rightarrow\infty}R^{x+1}\exp(-R)-\varepsilon^{x+1}\exp(-\varepsilon)
\]

\end_inset


\end_layout

\begin_layout Standard
(Because 
\begin_inset Formula $\exp(-R)$
\end_inset

 goes to zero faster than 
\begin_inset Formula $R^{x+1}$
\end_inset

 goes to infinity, and 
\begin_inset Formula $\varepsilon^{x+1}$
\end_inset

 goes to zero while 
\begin_inset Formula $\exp(-\varepsilon)$
\end_inset

 goes to 1.)
\end_layout

\begin_layout Standard
To recap, we've just found that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\int_{0}^{\infty}t^{x+1}\exp(-t)\,dt=(x+1)\int_{0}^{\infty}t^{x}\exp(-t)\,dt
\]

\end_inset


\end_layout

\begin_layout Standard
such that (1) can be satisfied by the function defined by an improper integral:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\Pi(x):=\int_{0}^{\infty}t^{x}\exp(-t)\,dt
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
And 
\begin_inset Formula $\Pi(0)=\int_{0}^{\infty}t^{0}\exp(-t)\,dt=\int_{0}^{\infty}\exp(-t)\,dt=\lim_{R\rightarrow\infty}\exp0-\exp(-R)=1-0=1$
\end_inset

, according with 
\begin_inset Formula $0!=1$
\end_inset

.
 Thus, we find that (2) is truly a generalized factorial function.
\end_layout

\begin_layout Subsection
Log Convexity and the Bohr–Mollerup Characterization
\end_layout

\begin_layout Standard
We've just shown that 
\begin_inset Formula $\Pi(x):=\int_{0}^{\infty}t^{x}\exp(-t)\,dt$
\end_inset

 is a generalized factorial function.
 But is it 
\emph on
the
\emph default
 generalized factorial? One could answer: No, there are infinitely many
 other functions that interpolate the points (
\begin_inset Formula $k,k!)$
\end_inset

: for example, 
\begin_inset Formula $\Pi(x)+\sin(\tau x)$
\end_inset

 will do.
 (Hidebound reactionaries would say 
\begin_inset Formula $\Gamma(x)+\sin(2\pi x)$
\end_inset

.) But that seems like 
\begin_inset Quotes eld
\end_inset

cheating.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
A bolder answer might be Yes—there might be an infinitude of functions passing
 through the points (
\begin_inset Formula $k,k!)$
\end_inset

, but 
\begin_inset Formula $\Pi(x)$
\end_inset

 is the only 
\begin_inset Quotes eld
\end_inset

good
\begin_inset Quotes erd
\end_inset

 one.
\end_layout

\begin_layout Standard
Explaining the sense of 
\begin_inset Quotes eld
\end_inset

good
\begin_inset Quotes erd
\end_inset

 that uniquely pinpoints 
\begin_inset Formula $\Pi(x)$
\end_inset

 will require some preparation and definitions—some doubtlessly familiar
 to the reader.
\end_layout

\begin_layout Subsubsection
(Log) Convexity Facts!
\end_layout

\begin_layout Standard
A function 
\begin_inset Formula $f$
\end_inset

 is said to be 
\emph on
convex
\emph default
 iff for all 
\begin_inset Formula $t\in[0,1]$
\end_inset

 and for all 
\begin_inset Formula $x_{1}$
\end_inset

 and 
\begin_inset Formula $x_{2}$
\end_inset

 in the domain, 
\begin_inset Formula $f(tx_{1}+(1-t)x_{2})\le tf(x_{1})+(1-t)f(x_{2})$
\end_inset

.
 If 
\begin_inset Formula $f$
\end_inset

 is twice-differentiable, then its second derivative is positive.
\end_layout

\begin_layout Standard
A consequence is 
\emph on
midpoint convexity
\emph default
 (just choose 
\begin_inset Formula $t=\frac{1}{2}$
\end_inset

): 
\begin_inset Formula 
\[
f\left(\frac{x_{1}+x_{2}}{2}\right)\le\frac{1}{2}(f(x_{1})+f(x_{2}))
\]

\end_inset


\end_layout

\begin_layout Standard
By an induction-like argument, midpoint convexity turns out to generalize
 to an arbitrary finite number of points:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
f\left(\frac{\sum_{k}x_{k}}{n}\right)\le\frac{1}{n}\sum_{k=1}^{n}f(x_{k})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Functions satisfying (3) are said to be 
\emph on
weaky convex
\emph default
 by authors such as Artin,
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Emil Artin, 
\emph on
The Gamma Function
\emph default
, Ch.
 1, 
\begin_inset Quotes eld
\end_inset

Convex Functions
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset

 although it's really not 
\emph on
much
\emph default
 weaker.
 (The only weakly convex but non-convex functions are non–Lebesgue-measurable
 monstrosities constructed using a Hamel basis for 
\begin_inset Formula $\mathbb{R}$
\end_inset

.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout

\emph on
https://math.stackexchange.com/questions/302684/weak-convexity-and-continuity
\end_layout

\end_inset

 The present author finds it hard to care less.)
\end_layout

\begin_layout Standard
A function 
\begin_inset Formula $f$
\end_inset

 is said to be 
\emph on
logarithmically convex
\emph default
 iff 
\begin_inset Formula $\log f$
\end_inset

 is convex.
\end_layout

\begin_layout Standard
I promise we're going somewhere with this.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard

\emph on
Proposition
\emph default
.
 If 
\begin_inset Formula $f$
\end_inset

 is logarithmically convex, then 
\begin_inset Formula $f\left(\frac{\sum_{k=1}^{n}x_{k}}{n}\right)^{n}\le\prod_{k=1}^{n}f(x_{k})$
\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Proof
\emph default
.
 
\begin_inset Quotes eld
\end_inset

Weak
\begin_inset Quotes erd
\end_inset

 logarithmic convexity and elementary log properties imply 
\begin_inset Formula $\log f\left(\frac{\sum_{k}x_{k}}{n}\right)\le\frac{1}{n}\sum_{k=1}^{n}\log f(x_{k})=\frac{1}{n}\log\prod_{k=1}^{n}f(x_{k})=\log\left(\prod_{k=1}^{n}f(x_{k})\right)^{\frac{1}{n}}=\log\sqrt[n]{\prod_{k=1}^{n}f(x_{k})}$
\end_inset

; exponentiating yields 
\begin_inset Formula $f\left(\frac{\sum_{k}x_{k}}{n}\right)\le\sqrt[n]{\prod_{k=1}^{n}f(x_{k})}$
\end_inset

 and taking it to the 
\begin_inset Formula $n$
\end_inset

th yields 
\begin_inset Formula $f\left(\frac{\sum_{k}x_{k}}{n}\right)^{n}\le\prod_{k=1}^{n}f(x_{k})$
\end_inset

, which is 
\emph on
quod erat demonstrandum
\emph default
.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard

\emph on
Theorem
\emph default
.
 The sum of logarithmically convex functions is logarithmically convex.
\end_layout

\begin_layout Standard
(Left as an exercise to the reader.)
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard

\emph on
Lemma
\emph default
.
 If 
\begin_inset Formula $f(x,t)$
\end_inset

 is logarithmically convex in 
\begin_inset Formula $x$
\end_inset

, then 
\begin_inset Formula $\int_{a}^{b}f(t,x)\,dt$
\end_inset

 is logarithmically convex in 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Proof
\emph default
.
 For 
\begin_inset Formula $n\in\mathbb{N}$
\end_inset

, let 
\begin_inset Formula $f_{n}:=\frac{b-a}{n}\sum_{k=0}^{n-1}f(x,\,a+k\left(\frac{b-a}{n}\right))$
\end_inset

.
 Then 
\begin_inset Formula $f_{n}$
\end_inset

 is logarithmically convex as the sum of logarithmically convex functions
 (by the previous theorem).
 But 
\begin_inset Formula $\lim_{n\rightarrow\infty}f_{n}$
\end_inset

 is the Reimann sum for 
\begin_inset Formula $\int_{a}^{b}f(t,x)\,dt$
\end_inset

, so that's logarithmically convex, too.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard

\emph on
Theorem
\emph default
.
 
\begin_inset Formula $\Pi(x)$
\end_inset

 is logarithmically convex.
\end_layout

\begin_layout Standard

\emph on
Proof
\emph default
.
 As a function of 
\begin_inset Formula $x$
\end_inset

, 
\begin_inset Formula $t^{x}\exp(-t)$
\end_inset

 is logarithmically convex, so by the lemma, 
\begin_inset Formula $\Pi(x):=\int_{0}^{\infty}t^{x}\exp(-t)\,dt$
\end_inset

 is, too.
\end_layout

\begin_layout Subsubsection
Bohr–Mollerup, and a Product Formula
\end_layout

\begin_layout Standard
Having intorduced the notion of logarithmic convexity, we are now in a position
 to present the following
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard

\emph on
Theorem
\emph default
 (Bohr and Mollerup via Artin).
 If a function 
\begin_inset Formula $f$
\end_inset

 satisfies the following conditions:
\end_layout

\begin_layout Enumerate
(Factorial-like recursion.) 
\begin_inset Formula $f(x+1)=(x+1)f(x)$
\end_inset


\end_layout

\begin_layout Enumerate
(Logarithmic convexity.) 
\begin_inset Formula $f$
\end_inset

 is logarithmically convex on 
\begin_inset Formula $x>-1$
\end_inset

.
\end_layout

\begin_layout Enumerate
(Initial condition.) 
\begin_inset Formula $f(0)=1$
\end_inset


\end_layout

\begin_layout Standard
then 
\begin_inset Formula $f(x)=\Pi(x)$
\end_inset

.
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard

\emph on
Proof
\emph default
.
 Suppose we have such an 
\begin_inset Formula $f$
\end_inset

.
 From factorial-like recursion and the initial condition, we know that 
\begin_inset Formula $f(n)=\Pi(n)=n!$
\end_inset

 for 
\begin_inset Formula $x\in\mathbb{N}$
\end_inset

.
 If we can show that 
\begin_inset Formula $f(x)=\Pi(x)$
\end_inset

 in an integer interval (
\emph on
e.g
\emph default
., 
\begin_inset Formula $x\in[0,1]$
\end_inset

), then factorial-like recursion will imply that 
\begin_inset Formula $f(x)=\Pi(x)$
\end_inset

 everywhere.
\end_layout

\begin_layout Standard
So fix 
\begin_inset Formula $x\in(0,1]$
\end_inset

.
 For a convex function, difference quotients 
\begin_inset Quotes eld
\end_inset

get bigger as you go to the right
\begin_inset Quotes erd
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\log f(n-1)-\log f(n)}{(n-1)-n}\le\frac{\log f(n+x)-\log f(n)}{(x+n)-n}\le\frac{\log f(n+1)-\log f(n)}{(n+1)-n}
\]

\end_inset


\end_layout

\begin_layout Standard
But at 
\begin_inset Formula $n\in\mathbb{N}$
\end_inset

, 
\begin_inset Formula $f(n)=n!$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\log(n-1)!-\log n!}{(n-1)-n}\le\frac{\log f(n+x)-\log n!}{(n+x)-n}\le\frac{\log(n+1)!-\log n!}{(n+1)-n}
\]

\end_inset


\end_layout

\begin_layout Standard
And then we do some more algebra:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\log\frac{(n-1)!}{n!}}{-1}\le\frac{\log f(x+n)-\log n!}{(x+n)-n}\le\frac{\log\frac{(n+1)!}{n!}}{1}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log(n)\le\frac{\log f(x+n)-\log n!}{x}\le\log(n+1)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
x\log(n)\le\log f(x+n)-\log n!\le x\log(n+1)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
x\log(n)+\log n!\le\log f(x+n)\cancel{-\log n!+\log n!}\le x\log(n+1)+\log n!
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log(n)^{x}+\log n!\le\log f(x+n)\le\log(n+1)^{x}+\log n!
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log n^{x}n!\le\log f(x+n)\le\log(n+1)^{x}n!
\]

\end_inset


\end_layout

\begin_layout Standard
The logarithm is monotonic, so we can drop them and keep the inequality:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
n^{x}n!\le f(x+n)\le(n+1)^{x}n!
\]

\end_inset


\end_layout

\begin_layout Standard
But we know from the factorial-like recursion that 
\begin_inset Formula $f(x+n)=f(x)\prod_{k=x+1}^{x+n}k$
\end_inset

, so
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{n^{x}n!}{\prod_{k=x+1}^{x+n}k}\le f(x)\le\frac{(n+1)^{x}n!}{\prod_{k=x+1}^{x+n}k}
\]

\end_inset


\end_layout

\begin_layout Standard
[TODO: figure out the last steps of the Bohr–Mollerup derivation]
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f(x+1)=\lim_{n\rightarrow\infty}\frac{n^{x}n!}{\prod_{k=x+1}^{x+n}k}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Logarithmic Convexity on Trial
\end_layout

\begin_layout Standard
[TODO: convexity is too weak, but log log &c.
 convexity is too strong]
\end_layout

\begin_layout Subsection
Analytic Continuation
\end_layout

\begin_layout Standard
[TODO: analytic continuation to 
\begin_inset Formula $\mathbb{C}$
\end_inset

]
\end_layout

\end_body
\end_document
